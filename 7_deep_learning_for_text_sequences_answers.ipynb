{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Deep Learning for Sequence Processing\n",
    "\n",
    "This lab introduces deep neural networks for processing sequential data, such as text, using recurrent neural networks. It will show you how to construct, train and test deep neural networks for text classification and sequence labelling using Pytorch. This builds on the simpler neural network from last week and applies deep learning to some of the datasets we worked with in earlier labs.\n",
    "\n",
    "\n",
    "### Aims\n",
    "* Learn how to construct a deep neural network with Pytorch.\n",
    "* Try out LSTMs for processing sequences of tokens.\n",
    "* Understand how to format the text data and use word embeddings as input to the network.\n",
    "* Learn how to train the model and use it to make predictions on a test set.\n",
    "* Apply the model to some of our previous tasks: sentiment classification (lab 2) and named entity recognition (lab 6). \n",
    "\n",
    "### Outline\n",
    "\n",
    "* (Re-)loading sentiment classification corpus (movie reviews).\n",
    "* Constructing a deep text classifier using a Bi-LSTM with feed-forward layers on top.\n",
    "* Training and test the text classifier on sentiment classification.\n",
    "* Using word embeddings as inputs instead of one-hot encodings.\n",
    "* (Re-)loading the re3d corpus (defence & security news). \n",
    "* Construct a sequence tagger using a Bi-LSTM.\n",
    "* Training and testing the sequence tagger on the NER task.\n",
    "\n",
    "### How To Complete This Lab\n",
    "\n",
    "Read the text and the code then look for 'TODOs' that instruct you to complete some missing code or answer a question. You don't have to stick rigidly to the lab -- feel free to explore other methods and data to help you understand what's going on or to go beyond this lab. \n",
    "\n",
    "Aim to work through the lab during the scheduled lab hour. You can also contact TAs with questions at the scheduled times throughout the week, or post your questions to our Teams conversation.\n",
    "\n",
    "The labs *will not be marked*. However, they will prepare you for the coursework, so try to keep up with the weekly labs and have fun with the exercises!\n",
    "\n",
    "### More Information\n",
    "\n",
    "Please see [chapter 9](https://web.stanford.edu/~jurafsky/slp3/9.pdf) of the Jurafsky and Martin book for more on this topic. \n",
    "\n",
    "Pytorch Tutorial: https://pytorch.org/tutorials/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Movie Review Classification\n",
    "\n",
    "In Lab 2 we managed to build a Naïve Bayes classifier. Can we build a classifier with a neural network (NN)? In this section, we will create a Bi-LSTM classifier that performs the sentiment analysis for the movie reviews by using PyTorch.\n",
    "\n",
    "Let's start by loading the movie review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "categories = movie_reviews.categories()\n",
    "# Get the data into a list, where each entry is a document tuple consisting of a list of tokens and a category label\n",
    "data = [\n",
    "        (list(movie_reviews.words(fileid)), category) \n",
    "        for category in categories\n",
    "        for fileid in movie_reviews.fileids(category)\n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Naïve Bayes classifier, we need to construct a dictionary from the dataset, which will be our set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39768\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "docs = [doc for doc, label in data]\n",
    "labels = [label for doc, label in data]\n",
    "\n",
    "words = []\n",
    "for doc in docs:\n",
    "    words += doc\n",
    "    \n",
    "wordfreqs = FreqDist(words)\n",
    "vocabulary = list(wordfreqs.keys())\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the train_test_split method from scikit learn to split the data into training, development, and test set as the given portions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 400 400\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "dev_size = 0.2\n",
    "train_size = 1 - test_size - dev_size\n",
    "\n",
    "# First split the test set from the train+dev data\n",
    "train_dev_data, test_data = train_test_split(data, train_size=train_size+dev_size, test_size=test_size)\n",
    "\n",
    "# Split the train data from the dev data\n",
    "train_data, dev_data = train_test_split(train_dev_data, train_size=(train_size)/(train_size + dev_size) , test_size=(dev_size)/(train_size + dev_size))\n",
    "print(len(train_data), len(dev_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start pre-processing our data, we separate them into reviews and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = [doc for doc, label in train_data]\n",
    "train_labels = [label for doc, label in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, a NN is constructed with 3 layers: input layer (embedding layer), hidden layer (CNN, RNN, etc.), output layer (full connected layer).\n",
    "\n",
    "To pass out data into the input layer, we first need to transfer the text data to numerical data so that we can embed it with the embedding layer. The easiest way to do so is create a dictionary that map the vocabularies into integer. e.g. {'hello':1, 'world':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1474,\n",
       " 2609,\n",
       " 55,\n",
       " 1517,\n",
       " 2537,\n",
       " 11,\n",
       " 39,\n",
       " 877,\n",
       " 418,\n",
       " 82,\n",
       " 808,\n",
       " 13,\n",
       " 6004,\n",
       " 16,\n",
       " 39,\n",
       " 33,\n",
       " 68,\n",
       " 2728,\n",
       " 317,\n",
       " 319,\n",
       " 4351,\n",
       " 754,\n",
       " 11,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 39,\n",
       " 877,\n",
       " 418,\n",
       " 82,\n",
       " 808,\n",
       " 13,\n",
       " 16389,\n",
       " 9301,\n",
       " 2390,\n",
       " 6004,\n",
       " 39,\n",
       " 566,\n",
       " 11,\n",
       " 130,\n",
       " 4351,\n",
       " 2932,\n",
       " 202,\n",
       " 23,\n",
       " 99,\n",
       " 13,\n",
       " 9286,\n",
       " 33,\n",
       " 1741,\n",
       " 513,\n",
       " 1137,\n",
       " 5058,\n",
       " 196,\n",
       " 24,\n",
       " 131,\n",
       " 16,\n",
       " 24,\n",
       " 163,\n",
       " 927,\n",
       " 33,\n",
       " 291,\n",
       " 2726,\n",
       " 11,\n",
       " 336,\n",
       " 205,\n",
       " 31,\n",
       " 808,\n",
       " 7558,\n",
       " 139,\n",
       " 8,\n",
       " 6765,\n",
       " 3298,\n",
       " 11,\n",
       " 65,\n",
       " 66,\n",
       " 537,\n",
       " 3543,\n",
       " 208,\n",
       " 16390,\n",
       " 16,\n",
       " 1990,\n",
       " 16,\n",
       " 7853,\n",
       " 3623,\n",
       " 86,\n",
       " 3567,\n",
       " 91,\n",
       " 1180,\n",
       " 8,\n",
       " 16389,\n",
       " 9301,\n",
       " 360,\n",
       " 86,\n",
       " 24,\n",
       " 39,\n",
       " 16391,\n",
       " 39,\n",
       " 16392,\n",
       " 91,\n",
       " 11,\n",
       " 464,\n",
       " 11,\n",
       " 65,\n",
       " 66,\n",
       " 7232,\n",
       " 7,\n",
       " 1266,\n",
       " 97,\n",
       " 16390,\n",
       " 16,\n",
       " 24,\n",
       " 360,\n",
       " 166,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 3047,\n",
       " 11,\n",
       " 24,\n",
       " 16390,\n",
       " 97,\n",
       " 1986,\n",
       " 11,\n",
       " 13,\n",
       " 24,\n",
       " 1179,\n",
       " 66,\n",
       " 695,\n",
       " 16,\n",
       " 39,\n",
       " 457,\n",
       " 329,\n",
       " 1371,\n",
       " 39,\n",
       " 551,\n",
       " 57,\n",
       " 24,\n",
       " 545,\n",
       " 11,\n",
       " 13,\n",
       " 205,\n",
       " 2939,\n",
       " 55,\n",
       " 24,\n",
       " 16391,\n",
       " 16392,\n",
       " 66,\n",
       " 138,\n",
       " 11,\n",
       " 6771,\n",
       " 603,\n",
       " 333,\n",
       " 11,\n",
       " 13,\n",
       " 2506,\n",
       " 7,\n",
       " 1266,\n",
       " 16,\n",
       " 24,\n",
       " 6268,\n",
       " 57,\n",
       " 68,\n",
       " 360,\n",
       " 11,\n",
       " 464,\n",
       " 11,\n",
       " 66,\n",
       " 55,\n",
       " 62,\n",
       " 592,\n",
       " 4351,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 5157,\n",
       " 11,\n",
       " 13,\n",
       " 33,\n",
       " 68,\n",
       " 754,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 1081,\n",
       " 16,\n",
       " 55,\n",
       " 224,\n",
       " 6431,\n",
       " 252,\n",
       " 53,\n",
       " 13777,\n",
       " 97,\n",
       " 662,\n",
       " 1411,\n",
       " 16,\n",
       " 38,\n",
       " 224,\n",
       " 283,\n",
       " 8,\n",
       " 7414,\n",
       " 7415,\n",
       " 4145,\n",
       " 82,\n",
       " 1411,\n",
       " 6104,\n",
       " 11,\n",
       " 151,\n",
       " 23,\n",
       " 11851,\n",
       " 2077,\n",
       " 13,\n",
       " 410,\n",
       " 9251,\n",
       " 2856,\n",
       " 1093,\n",
       " 566,\n",
       " 965,\n",
       " 48,\n",
       " 7,\n",
       " 283,\n",
       " 8,\n",
       " 882,\n",
       " 11608,\n",
       " 11,\n",
       " 1167,\n",
       " 1032,\n",
       " 44,\n",
       " 65,\n",
       " 2218,\n",
       " 1280,\n",
       " 612,\n",
       " 8,\n",
       " 58,\n",
       " 2885,\n",
       " 6529,\n",
       " 16,\n",
       " 1717,\n",
       " 24,\n",
       " 44,\n",
       " 393,\n",
       " 161,\n",
       " 7,\n",
       " 283,\n",
       " 2546,\n",
       " 9605,\n",
       " 11,\n",
       " 13,\n",
       " 161,\n",
       " 7,\n",
       " 611,\n",
       " 24,\n",
       " 39,\n",
       " 5157,\n",
       " 39,\n",
       " 849,\n",
       " 44,\n",
       " 62,\n",
       " 1453,\n",
       " 3928,\n",
       " 107,\n",
       " 940,\n",
       " 16,\n",
       " 434,\n",
       " 62,\n",
       " 66,\n",
       " 11,\n",
       " 14,\n",
       " 24,\n",
       " 261,\n",
       " 13,\n",
       " 2194,\n",
       " 107,\n",
       " 1088,\n",
       " 24,\n",
       " 465,\n",
       " 2090,\n",
       " 11,\n",
       " 303,\n",
       " 68,\n",
       " 66,\n",
       " 4810,\n",
       " 6723,\n",
       " 7,\n",
       " 283,\n",
       " 20,\n",
       " 97,\n",
       " 48,\n",
       " 386,\n",
       " 10682,\n",
       " 16,\n",
       " 24,\n",
       " 261,\n",
       " 11,\n",
       " 142,\n",
       " 7713,\n",
       " 252,\n",
       " 6766,\n",
       " 11,\n",
       " 8,\n",
       " 1374,\n",
       " 1728,\n",
       " 163,\n",
       " 11,\n",
       " 8917,\n",
       " 24,\n",
       " 163,\n",
       " 33,\n",
       " 8,\n",
       " 16084,\n",
       " 11,\n",
       " 13,\n",
       " 6348,\n",
       " 666,\n",
       " 44,\n",
       " 16,\n",
       " 92,\n",
       " 93,\n",
       " 385,\n",
       " 6349,\n",
       " 387,\n",
       " 11,\n",
       " 566,\n",
       " 101,\n",
       " 8,\n",
       " 1058,\n",
       " 23,\n",
       " 246,\n",
       " 1253,\n",
       " 16,\n",
       " 434,\n",
       " 24,\n",
       " 568,\n",
       " 393,\n",
       " 2868,\n",
       " 11,\n",
       " 14,\n",
       " 62,\n",
       " 277,\n",
       " 283,\n",
       " 97,\n",
       " 1015,\n",
       " 11,\n",
       " 27,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 1177,\n",
       " 14750,\n",
       " 3397,\n",
       " 16,\n",
       " 33,\n",
       " 589,\n",
       " 11,\n",
       " 24,\n",
       " 2323,\n",
       " 66,\n",
       " 16393,\n",
       " 1708,\n",
       " 11,\n",
       " 13,\n",
       " 24,\n",
       " 9508,\n",
       " 156,\n",
       " 439,\n",
       " 1210,\n",
       " 16,\n",
       " 3567,\n",
       " 13,\n",
       " 4130,\n",
       " 93,\n",
       " 130,\n",
       " 10842,\n",
       " 130,\n",
       " 136,\n",
       " 1802,\n",
       " 11,\n",
       " 82,\n",
       " 24,\n",
       " 2323,\n",
       " 156,\n",
       " 9339,\n",
       " 7,\n",
       " 7290,\n",
       " 602,\n",
       " 16,\n",
       " 92,\n",
       " 66,\n",
       " 410,\n",
       " 386,\n",
       " 33,\n",
       " 68,\n",
       " 163,\n",
       " 11,\n",
       " 27,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 3532,\n",
       " 33,\n",
       " 85,\n",
       " 20,\n",
       " 1412,\n",
       " 210,\n",
       " 11,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 101,\n",
       " 16394,\n",
       " 7,\n",
       " 43,\n",
       " 16,\n",
       " 24,\n",
       " 1260,\n",
       " 472,\n",
       " 97,\n",
       " 171,\n",
       " 24,\n",
       " 1000,\n",
       " 11,\n",
       " 16395,\n",
       " 24,\n",
       " 131,\n",
       " 11,\n",
       " 13,\n",
       " 566,\n",
       " 23,\n",
       " 2171,\n",
       " 24,\n",
       " 131,\n",
       " 33,\n",
       " 24,\n",
       " 386,\n",
       " 11,\n",
       " 62,\n",
       " 5619,\n",
       " 16396,\n",
       " 602,\n",
       " 16,\n",
       " 24,\n",
       " 16397,\n",
       " 93,\n",
       " 1853,\n",
       " 16,\n",
       " 8139,\n",
       " 11,\n",
       " 434,\n",
       " 873,\n",
       " 413,\n",
       " 414,\n",
       " 16,\n",
       " 3567,\n",
       " 66,\n",
       " 1853,\n",
       " 16,\n",
       " 8139,\n",
       " 11,\n",
       " 279,\n",
       " 687,\n",
       " 39,\n",
       " 40,\n",
       " 156,\n",
       " 58,\n",
       " 94,\n",
       " 612,\n",
       " 5547,\n",
       " 1179,\n",
       " 11,\n",
       " 195,\n",
       " 962,\n",
       " 4819,\n",
       " 198,\n",
       " 16,\n",
       " 24,\n",
       " 4058,\n",
       " 547,\n",
       " 93,\n",
       " 97,\n",
       " 12493,\n",
       " 11,\n",
       " 82,\n",
       " 136,\n",
       " 85,\n",
       " 130,\n",
       " 8,\n",
       " 181,\n",
       " 1171,\n",
       " 4694,\n",
       " 4213,\n",
       " 82,\n",
       " 8,\n",
       " 4923,\n",
       " 3309,\n",
       " 11,\n",
       " 8,\n",
       " 5711,\n",
       " 4592,\n",
       " 82,\n",
       " 16398,\n",
       " 11,\n",
       " 13,\n",
       " 38,\n",
       " 1453,\n",
       " 283,\n",
       " 24,\n",
       " 155,\n",
       " 2234,\n",
       " 6762,\n",
       " 39,\n",
       " 1517,\n",
       " 15344,\n",
       " 39,\n",
       " 333,\n",
       " 16,\n",
       " 522,\n",
       " 14093,\n",
       " 94,\n",
       " 1935,\n",
       " 11,\n",
       " 464,\n",
       " 16,\n",
       " 4351,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 857,\n",
       " 3775,\n",
       " 82,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 370,\n",
       " 11,\n",
       " 4744,\n",
       " 13,\n",
       " 136,\n",
       " 11,\n",
       " 27,\n",
       " 24,\n",
       " 163,\n",
       " 166,\n",
       " 143,\n",
       " 94,\n",
       " 16,\n",
       " 144,\n",
       " 1697,\n",
       " 3505,\n",
       " 11,\n",
       " 4351,\n",
       " 66,\n",
       " 8,\n",
       " 1959,\n",
       " 754,\n",
       " 23,\n",
       " 2336,\n",
       " 23,\n",
       " 558,\n",
       " 16,\n",
       " 62,\n",
       " 857,\n",
       " 283,\n",
       " 8,\n",
       " 216,\n",
       " 121,\n",
       " 16399,\n",
       " 53,\n",
       " 62,\n",
       " 39,\n",
       " 40,\n",
       " 296,\n",
       " 94,\n",
       " 11,\n",
       " 27,\n",
       " 24,\n",
       " 894,\n",
       " 143,\n",
       " 475,\n",
       " 11,\n",
       " 13,\n",
       " 436,\n",
       " 23,\n",
       " 24,\n",
       " 163,\n",
       " 93,\n",
       " 3532,\n",
       " 116,\n",
       " 16,\n",
       " 27,\n",
       " 1181,\n",
       " 580,\n",
       " 39,\n",
       " 103,\n",
       " 94,\n",
       " 495,\n",
       " 7,\n",
       " 541,\n",
       " 4351,\n",
       " 139,\n",
       " 24,\n",
       " 5668,\n",
       " 23,\n",
       " 658,\n",
       " 11,\n",
       " 270,\n",
       " 336,\n",
       " 62,\n",
       " 3431,\n",
       " 39,\n",
       " 103,\n",
       " 198,\n",
       " 8065,\n",
       " 16,\n",
       " 8,\n",
       " 94,\n",
       " 3332,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 421,\n",
       " 16,\n",
       " 8,\n",
       " 4817,\n",
       " 16,\n",
       " 300,\n",
       " 557,\n",
       " 8143,\n",
       " 69,\n",
       " 208,\n",
       " 2278,\n",
       " 8144,\n",
       " 42,\n",
       " 3511]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doc_encoding(docs, vocabulary):\n",
    "    \n",
    "    # create word to id dictionary\n",
    "    word_to_id = {w:i+1 for i,w in enumerate(vocabulary)}\n",
    "    # convert docs to token-id lists\n",
    "    encode_docs = [[word_to_id[word] for word in tokens_doc] for tokens_doc in docs]\n",
    "\n",
    "    return encode_docs\n",
    "\n",
    "train_doc_encode = doc_encoding(train_docs, vocabulary)\n",
    "train_doc_encode[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the each word in the document is now encoded with given interger.\n",
    "\n",
    "Next, let's do the same for the labels. Label the `'pos'` as `1` and `'neg'` as `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_encoding(labels):\n",
    "    \n",
    "    encode_label = [1 if label =='pos' else 0 for label in labels] \n",
    "    \n",
    "    return np.array(encode_label)\n",
    "\n",
    "train_label_encode = label_encoding(train_labels)\n",
    "train_label_encode[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is more efficient to process multiple sequences (documents) a batch of data than one-by-one. However, this requires that the sequences all have the same size. Thus, we need to pad/truncate the reviews into the same length. The RNN will ignore the special pad tokens. Let's plot a histogram to understand the length distribution of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the document length: 791.91\n",
      "Median of the document length: 745.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 76., 509., 763., 415., 140.,  56.,  25.,  12.,   1.,   3.]),\n",
       " array([  19.,  305.,  591.,  877., 1163., 1449., 1735., 2021., 2307.,\n",
       "        2593., 2879.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "rv_l = [len(d) for d in docs]\n",
    "print('Mean of the document length: {}'.format(statistics.mean(rv_l)))\n",
    "print('Median of the document length: {}'.format(statistics.median(rv_l)))\n",
    "\n",
    "plt.hist(rv_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most of the reviews are less than 800 words, the sequence length will be 800.\n",
    "\n",
    "Note that, for RNN/LSTM, the network is more likely to remember the input at the end of the sequence. While padding, we add `0` at the beginning of the sequence instead of the end.\n",
    "\n",
    "**TODO 1.1:** Write a function that pads or truncates the data to a given sequence length. The first argument, doc_encode, is a list where each entry corresponds to a document, represented as a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,  1474,  2609,    55,  1517,  2537,\n",
       "          11,    39,   877,   418,    82,   808,    13,  6004,    16,\n",
       "          39,    33,    68,  2728,   317,   319,  4351,   754,    11,\n",
       "          62,    39,    40,    39,   877,   418,    82,   808,    13,\n",
       "       16389,  9301,  2390,  6004,    39,   566,    11,   130,  4351,\n",
       "        2932,   202,    23,    99,    13,  9286,    33,  1741,   513,\n",
       "        1137,  5058,   196,    24,   131,    16,    24,   163,   927,\n",
       "          33,   291,  2726,    11,   336,   205,    31,   808,  7558,\n",
       "         139,     8,  6765,  3298,    11,    65,    66,   537,  3543,\n",
       "         208, 16390,    16,  1990,    16,  7853,  3623,    86,  3567,\n",
       "          91,  1180,     8, 16389,  9301,   360,    86,    24,    39,\n",
       "       16391,    39, 16392,    91,    11,   464,    11,    65,    66,\n",
       "        7232,     7,  1266,    97, 16390,    16,    24,   360,   166,\n",
       "          62,    39,    40,  3047,    11,    24, 16390,    97,  1986,\n",
       "          11,    13,    24,  1179,    66,   695,    16,    39,   457,\n",
       "         329,  1371,    39,   551,    57,    24,   545,    11,    13,\n",
       "         205,  2939,    55,    24, 16391, 16392,    66,   138,    11,\n",
       "        6771,   603,   333,    11,    13,  2506,     7,  1266,    16,\n",
       "          24,  6268,    57,    68,   360,    11,   464,    11,    66,\n",
       "          55,    62,   592,  4351,    62,    39,    40,  5157,    11,\n",
       "          13,    33,    68,   754,    16,    16,    16,    16,    62,\n",
       "          39,    40,  1081,    16,    55,   224,  6431,   252,    53,\n",
       "       13777,    97,   662,  1411,    16,    38,   224,   283,     8,\n",
       "        7414,  7415,  4145,    82,  1411,  6104,    11,   151,    23,\n",
       "       11851,  2077,    13,   410,  9251,  2856,  1093,   566,   965,\n",
       "          48,     7,   283,     8,   882, 11608,    11,  1167,  1032,\n",
       "          44,    65,  2218,  1280,   612,     8,    58,  2885,  6529,\n",
       "          16,  1717,    24,    44,   393,   161,     7,   283,  2546,\n",
       "        9605,    11,    13,   161,     7,   611,    24,    39,  5157,\n",
       "          39,   849,    44,    62,  1453,  3928,   107,   940,    16,\n",
       "         434,    62,    66,    11,    14,    24,   261,    13,  2194,\n",
       "         107,  1088,    24,   465,  2090,    11,   303,    68,    66,\n",
       "        4810,  6723,     7,   283,    20,    97,    48,   386, 10682,\n",
       "          16,    24,   261,    11,   142,  7713,   252,  6766,    11,\n",
       "           8,  1374,  1728,   163,    11,  8917,    24,   163,    33,\n",
       "           8, 16084,    11,    13,  6348,   666,    44,    16,    92,\n",
       "          93,   385,  6349,   387,    11,   566,   101,     8,  1058,\n",
       "          23,   246,  1253,    16,   434,    24,   568,   393,  2868,\n",
       "          11,    14,    62,   277,   283,    97,  1015,    11,    27,\n",
       "          62,    39,    40,  1177, 14750,  3397,    16,    33,   589,\n",
       "          11,    24,  2323,    66, 16393,  1708,    11,    13,    24,\n",
       "        9508,   156,   439,  1210,    16,  3567,    13,  4130,    93,\n",
       "         130, 10842,   130,   136,  1802,    11,    82,    24,  2323,\n",
       "         156,  9339,     7,  7290,   602,    16,    92,    66,   410,\n",
       "         386,    33,    68,   163,    11,    27,    62,    39,    40,\n",
       "        3532,    33,    85,    20,  1412,   210,    11,    62,    39,\n",
       "          40,   101, 16394,     7,    43,    16,    24,  1260,   472,\n",
       "          97,   171,    24,  1000,    11, 16395,    24,   131,    11,\n",
       "          13,   566,    23,  2171,    24,   131,    33,    24,   386,\n",
       "          11,    62,  5619, 16396,   602,    16,    24, 16397,    93,\n",
       "        1853,    16,  8139,    11,   434,   873,   413,   414,    16,\n",
       "        3567,    66,  1853,    16,  8139,    11,   279,   687,    39,\n",
       "          40,   156,    58,    94,   612,  5547,  1179,    11,   195,\n",
       "         962,  4819,   198,    16,    24,  4058,   547,    93,    97,\n",
       "       12493,    11,    82,   136,    85,   130,     8,   181,  1171,\n",
       "        4694,  4213,    82,     8,  4923,  3309,    11,     8,  5711,\n",
       "        4592,    82, 16398,    11,    13,    38,  1453,   283,    24,\n",
       "         155,  2234,  6762,    39,  1517, 15344,    39,   333,    16,\n",
       "         522, 14093,    94,  1935,    11,   464,    16,  4351,    11,\n",
       "          14,    11,   857,  3775,    82,    62,    39,    40,   370,\n",
       "          11,  4744,    13,   136,    11,    27,    24,   163,   166,\n",
       "         143,    94,    16,   144,  1697,  3505,    11,  4351,    66,\n",
       "           8,  1959,   754,    23,  2336,    23,   558,    16,    62,\n",
       "         857,   283,     8,   216,   121, 16399,    53,    62,    39,\n",
       "          40,   296,    94,    11,    27,    24,   894,   143,   475,\n",
       "          11,    13,   436,    23,    24,   163,    93,  3532,   116,\n",
       "          16,    27,  1181,   580,    39,   103,    94,   495,     7,\n",
       "         541,  4351,   139,    24,  5668,    23,   658,    11,   270,\n",
       "         336,    62,  3431,    39,   103,   198,  8065,    16,     8,\n",
       "          94,  3332,    11,    14,    11,   421,    16,     8,  4817,\n",
       "          16,   300,   557,  8143,    69,   208,  2278,  8144,    42,\n",
       "        3511])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_text(doc_encode, seq_length):\n",
    "    ###WRITE YOUR OWN CODE HERE\n",
    "    reviews = []\n",
    "    for doc in doc_encode:\n",
    "        if len(doc) >= seq_length:\n",
    "            reviews.append(doc[:seq_length])\n",
    "        else:\n",
    "            reviews.append([0]*(seq_length-len(doc)) + doc)\n",
    "        \n",
    "    return np.array(reviews)\n",
    "\n",
    "sequence_length = 1000  # truncate all docs longer than this. Padd all docs shorter than this.\n",
    "train_padded_doc = pad_text(train_doc_encode, seq_length=sequence_length)\n",
    "train_padded_doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pytorch, NN takes tensor, a multi-dimensional matrix containing elements of a single data type, as the input. Then a `Dataloader` is built to separate the dataset into smaller batches and suffer them.\n",
    "\n",
    "Note that for numpy array, we need to apply `torch.from_numpy()` method to transfer it into a tensor while building the dataset.\n",
    "\n",
    "TensorDataset: http://man.hubwiz.com/docset/PyTorch.docset/Contents/Resources/Documents/data.html\n",
    "DataLoader: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_tensor = TensorDataset(torch.from_numpy(train_padded_doc), torch.from_numpy(train_label_encode))\n",
    "train_loader = DataLoader(train_tensor, batch_size = batch_size, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the development and test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_docs = [doc for doc, label in dev_data]\n",
    "dev_labels = [label for doc, label in dev_data]\n",
    "dev_doc_encode = doc_encoding(dev_docs, vocabulary)\n",
    "dev_label_encode = label_encoding(dev_labels)\n",
    "dev_padded_doc = pad_text(dev_doc_encode, sequence_length)\n",
    "dev_tensor = TensorDataset(torch.from_numpy(dev_padded_doc), torch.from_numpy(dev_label_encode))\n",
    "dev_loader = DataLoader(dev_tensor, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_docs = [doc for doc, label in test_data]\n",
    "test_labels = [label for doc, label in test_data]\n",
    "test_doc_encode = doc_encoding(test_docs, vocabulary)\n",
    "test_label_encode = label_encoding(test_labels)\n",
    "test_padded_doc = pad_text(test_doc_encode, sequence_length)\n",
    "test_tensor = TensorDataset(torch.from_numpy(test_padded_doc), torch.from_numpy(test_label_encode))\n",
    "test_loader = DataLoader(test_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After processing the data, now it's time for us to build the network!\n",
    "\n",
    "For movie review classification, we intend to build a NN with three different layers. \n",
    "### Embedding layer\n",
    "In the embedding layer, the network will create embeddings for the index with a given embedding dimension. The module `nn.Embedding()` creates a simple lookup table that stores embeddings of a fixed dictionary and size. This module is often used to store word embeddings and retrieve them using indices. The module's input is a list of indices, and the output is the corresponding word embeddings.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "### BiLSTM layers\n",
    "Pytorch provides a `nn.LSTM()` module for applying a multi-layer LSTM to an input sequence. With this module, you can also build the BiLSTM we need for this lab. Please check the documentation to see how to construct the object as a bidirectional layer.\n",
    "\n",
    "Note that for BiLSTM, the output size has `2*hidden_units`. Becasue the output comes from both directions.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "### Full connected layer\n",
    "Fully Connected layers in a neural network are those layers where all the inputs from one layer are connected to every activation unit of the next layer. In classification task, a full connected layer aims to map the output from the hidden layer to the number of class. Then a logistic function can be implemented to determine the class. Here we will use `nn.Linear()` to build a linear layer to reduce the LSTM output dimensions.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "**TODO 1.2:** Construct the NN with three layers, and develop the forward function that feedforward the input data and generate an output in `(batch_size, n_class)` dimension.\n",
    "\n",
    "**Hint:** The following code is a basic DNN class that contains an init function and a feedforward function. What you need to do is modifying the hidden layer into a BiLSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, n_hidden, n_layers, n_class):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        \n",
    "        ###WRITE YOUR OWN CODE HERE:  \n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed) # embedding layer\n",
    "#         self.layer = nn.Linear(n_embed, n_hidden) # Hidden layer\n",
    "#         self.activation = nn.Sigmoid() # Hidden layer\n",
    "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, bidirectional=True) # BiLSTM layer\n",
    "        self.fc = nn.Linear(n_hidden*2, n_class) # Full connection layer\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):\n",
    "        ###WRITE YOUR OWN CODE HERE\n",
    "                                                        # INPUT   :  (batch_size, seq_length)\n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "#         linear_out = self.layer(embedded_words)         # (batch_size, seq_length, n_hidden)\n",
    "#         linear_out = self.activation(linear_out)        # (batch_size, seq_length, n_hidden)\n",
    "#         linear_out = linear_out[:,-1,:]                 # (batch_size, 2*n_hidden)\n",
    "        lstm_out, matrix = self.lstm(embedded_words)    # (batch_size, seq_length, 2*n_hidden)\n",
    "        lstm_out = lstm_out[:,-1,:]                     # (batch_size, 2*n_hidden)\n",
    "        fc_out = self.fc(lstm_out)                      # (batch_size, n_class)\n",
    "\n",
    "        return fc_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1.3:** Create a NN with the BiLSTM class we wrote. \n",
    "\n",
    "**Hint:** `model = BiLSTM(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(vocabulary)\n",
    "n_embed = 100  # number of dimension for embeddings\n",
    "n_hidden = 64 # number of hidden unit for BiLSTM\n",
    "n_layers = 1   # number of BiLSTM layer\n",
    "n_output = 2   # 1 (\"pos\") and 0 (\"neg\")\n",
    "\n",
    "###WRITE YOUR OWN CODE HERE\n",
    "model = BiLSTM(n_vocab, n_embed, n_hidden, n_layers, n_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After desigining our network, we need to create a train function to calculate the loss for each input and perform backpropagation to optimise the network. During training, the weights of all the layer will be updated.\n",
    "\n",
    "We build a training function to train the NN with given epoches. The function also prints the performance of both training and development set during the training.\n",
    "\n",
    "**TODO 1.4:** Following the training, complete the validation part in the function. So that it can evaluate network with the development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(epoch, model, train_data, dev_data, loss_fn, optimizer):\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        train_correct = 0\n",
    "        dev_correct = 0\n",
    "        train_size = 0\n",
    "        dev_size = 0\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for inputs, labels in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, labels)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct = torch.sum(predicted == labels).item()\n",
    "            train_correct += correct\n",
    "            train_size += torch.numel(labels)\n",
    "            \n",
    "        train_accuracy = train_correct/train_size*100\n",
    "            \n",
    "        model.eval()\n",
    "        dev_losses = []\n",
    "\n",
    "        for dev_inputs, dev_labels in dev_data:\n",
    "            ###WRITE YOUR OWN CODE HERE\n",
    "            dev_output = model(dev_inputs)\n",
    "            dev_loss = loss_fn(dev_output, dev_labels)\n",
    "            dev_losses.append(dev_loss.item())\n",
    "            _, predicted = torch.max(dev_output, 1)\n",
    "            correct = torch.sum(predicted == dev_labels).item()\n",
    "            dev_correct += correct\n",
    "            dev_size += torch.numel(dev_labels)\n",
    "            \n",
    "        dev_accuracy = dev_correct/dev_size*100\n",
    "        \n",
    "        print(\"Epoch: {}/{}\".format((e+1), epoch),\n",
    "              \"Training Loss: {:.4f}\".format(np.mean(train_losses)),\n",
    "              \"Validation Loss: {:.4f}\".format(np.mean(dev_losses)),\n",
    "              \"Training Accuracy: {:.4f}%\".format(train_accuracy),\n",
    "              \"Validation Accuracy: {:.4f}%\".format(dev_accuracy))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step before we start training is defining the loss function and optimizer.\n",
    "\n",
    "Here we use cross-entropy loss and Adam optimization. Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. The module `nn.CrossEntropyLoss()` combines `LogSoftmax` and `NLLLoss` in one single class so that we don't have to implement an extra softmax layer.\n",
    "\n",
    "Cross Entropy Loss: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\n",
    "Adam optimization: https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "**TODO 1.5:** Define the loss function and optimizer. And train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 Training Loss: 0.6975 Validation Loss: 0.6977 Training Accuracy: 50.2500% Validation Accuracy: 48.7500%\n",
      "Epoch: 2/5 Training Loss: 0.6889 Validation Loss: 0.6971 Training Accuracy: 54.2500% Validation Accuracy: 49.5000%\n",
      "Epoch: 3/5 Training Loss: 0.6826 Validation Loss: 0.6973 Training Accuracy: 56.8333% Validation Accuracy: 49.7500%\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "###WRITE YOUR OWN CODE HERE\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epoch = 5  # train loss << validation loss from ~ epoch 3 or 4\n",
    "trained_model = train_nn(epoch, model, train_loader, dev_loader, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1.6:** Evaluate the model on test set. Complete the code to count the correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 57.50%\n"
     ]
    }
   ],
   "source": [
    "trained_model.eval()\n",
    "\n",
    "test_losses = []\n",
    "correct = 0  # count the number of correct classification labels\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    test_output = trained_model(inputs)\n",
    "    loss = loss_fn(test_output, labels)\n",
    "    test_losses.append(loss.item())\n",
    "    _, predicted = torch.max(test_output, 1)\n",
    "    \n",
    "    ###WRITE YOUR OWN CODE HERE\n",
    "    c = torch.sum(predicted == labels).item()\n",
    "    correct += c\n",
    "    \n",
    "accuracy = correct/len(test_loader.dataset)*100\n",
    "\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy))\n",
    "# print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use word embeddings as inputs instead of one-hot encodings.\n",
    "\n",
    "As in lab 4, let's train a word2vec embedding with the movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39768"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# create gensim model as in lab 4\n",
    "sentences = []\n",
    "for category in categories:\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        sentences.extend(movie_reviews.sents(fileid))\n",
    "\n",
    "w2v = word2vec.Word2Vec(sentences, sg=1, min_count=1, window=3, size=n_embed)\n",
    "\n",
    "weights = w2v.wv.vectors\n",
    "len(w2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1.7:** Modify the embedding layer of the BiLSTM class by adding word2vec weights with `nn.Embedding.from_pretrained()`.\n",
    "\n",
    "**Hint:** The weights for all the layers will be updated during. However, as we applied a trained embedding methods we don't want the weights of embedding layer updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2VBiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_embed, n_hidden, n_layers, n_class, weights):\n",
    "        super(W2VBiLSTM, self).__init__()\n",
    "        \n",
    "        weights = torch.FloatTensor(weights) \n",
    "        \n",
    "        ###WRITE YOUR OWN CODE HERE\n",
    "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
    "        self.embedding.requires_grad = False\n",
    "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, bidirectional=True) # BiLSTM layer\n",
    "        self.fc = nn.Linear(n_hidden*2, n_class) # Full connection layer\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):\n",
    "        ###WRITE YOUR OWN CODE HERE\n",
    "                                                        # INPUT   :  (batch_size, seq_length)\n",
    "        embedded_words = self.embedding(input_words)    # (batch_size, seq_length, n_embed)\n",
    "        lstm_out, matrix = self.lstm(embedded_words)    # (batch_size, seq_length, 2*n_hidden)\n",
    "        lstm_out = lstm_out[:,-1,:]                     # (batch_size, 2*n_hidden)\n",
    "        fc_out = self.fc(lstm_out)                      # (batch_size, n_class)\n",
    "\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1.8:** Create the model, initialise the loss function and optimizer, and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 Training Loss: 0.6925 Validation Loss: 0.6915 Training Accuracy: 53.2500% Validation Accuracy: 51.5000%\n",
      "Epoch: 2/5 Training Loss: 0.6883 Validation Loss: 0.6897 Training Accuracy: 53.0833% Validation Accuracy: 54.0000%\n",
      "Epoch: 3/5 Training Loss: 0.6856 Validation Loss: 0.6905 Training Accuracy: 54.1667% Validation Accuracy: 53.0000%\n",
      "Epoch: 4/5 Training Loss: 0.6808 Validation Loss: 0.6895 Training Accuracy: 56.0000% Validation Accuracy: 52.2500%\n",
      "Epoch: 5/5 Training Loss: 0.6776 Validation Loss: 0.6916 Training Accuracy: 56.7500% Validation Accuracy: 52.0000%\n"
     ]
    }
   ],
   "source": [
    "epoch = 5\n",
    "\n",
    "###WRITE YOUR OWN CODE HERE\n",
    "w2v_model = W2VBiLSTM(n_embed, n_hidden, n_layers, n_output, weights)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(w2v_model.parameters(), lr=0.001)\n",
    "\n",
    "w2v_model = train_nn(epoch, w2v_model, train_loader, dev_loader, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1.9:** Evaluate the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 57.50%\n"
     ]
    }
   ],
   "source": [
    "w2v_model.eval()\n",
    "\n",
    "###WRITE YOUR OWN CODE HERE\n",
    "test_losses = []\n",
    "correct = 0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    test_output = trained_model(inputs)\n",
    "    loss = loss_fn(test_output, labels)\n",
    "    test_losses.append(loss.item())\n",
    "    _, predicted = torch.max(test_output, 1)\n",
    "    c = torch.sum(predicted == labels).item()\n",
    "    correct += c\n",
    "    \n",
    "accuracy = correct/len(test_loader.dataset)*100\n",
    "\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy))\n",
    "# print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Named Entity Recognition (Optional)\n",
    "\n",
    "In this section, we will construct a sequence tagger using a Bi-LSTM. The most significant difference between NER and sentiment classification is that in NER, we take the output from every time steps to the output layer for classification. However, in sentiment classification, we only used the last time step.\n",
    "\n",
    "As in lab 6, let's start by loading the re3d dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 documents\n",
      "Loaded 2433 non-overlapping entities in total.\n",
      "We have loaded a dataset with 953 sentences.\n"
     ]
    }
   ],
   "source": [
    "from lab6_data.load_re3d import load_re3d_data\n",
    "\n",
    "sentences, tags, tag_names_to_idx, tag_idx_to_names, relation_pairs = load_re3d_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we separate the data into training and test set. Comparing to lab 6, we only keep the taggers and remove the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 762\n",
      "Number of test sentences: 191\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(len(sentences)):\n",
    "    tagged_words = list(sentences[i]), list(tag_idx_to_names[tags[i]])\n",
    "    data.append(list(tagged_words))\n",
    "\n",
    "train_set, test_set = train_test_split(\n",
    "    data,\n",
    "    train_size=0.80,\n",
    "    test_size=0.20,\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "train_sentences, train_labels = zip(*train_set)\n",
    "test_sentences, test_labels = zip(*test_set)\n",
    "print(f'Number of training sentences: {len(train_sentences)}')\n",
    "print(f'Number of test sentences: {len(test_sentences)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples of the sentences and the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence example: ['We', 'will', 'continue', 'to', 'strike', 'ISIL', 'military', 'targets', 'in', 'support', 'of', 'our', 'partners', 'in', 'order', 'to', 'defeat', 'ISIL', 'in', 'Iraq', '.']\n",
      "Tag example: (['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Person', 'I-Person', 'I-Person', 'I-Person', 'I-Person', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Temporal', 'I-Temporal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-Organisation', 'I-Organisation', 'I-Organisation', 'O', 'O', 'B-Organisation', 'O', 'O', 'O', 'B-Weapon', 'I-Weapon', 'O', 'B-Location', 'I-Location', 'I-Location', 'I-Location', 'I-Location', 'O', 'B-Location', 'I-Location', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'O', 'O', 'O', 'B-Location', 'I-Location', 'O', 'B-Location', 'O'], ['O', 'O', 'B-Person', 'I-Person', 'O', 'O', 'B-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-Location', 'I-Location', 'O', 'O', 'B-Location', 'I-Location', 'O', 'B-MilitaryPlatfo', 'I-MilitaryPlatfo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Location', 'I-Location', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Location', 'I-Location', 'I-Location', 'I-Location', 'O'], ['O', 'O', 'O', 'O', 'B-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'I-Organisation', 'O'])\n"
     ]
    }
   ],
   "source": [
    "print('Sentence example: {}'.format(train_sentences[0]))\n",
    "print(f'Tag example: {train_labels[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous task, a dictionary of the words is required as input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4381\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "words = []\n",
    "for s in sentences:\n",
    "    words.extend(s)\n",
    "wordfreqs = FreqDist(words)\n",
    "vocabulary_ner = list(wordfreqs.keys())\n",
    "print(len(vocabulary_ner))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tags, we add one more feature `'PAD'` that represents the paddings for the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 32\n",
      "{'O': 1, 'B-DocumentReference': 2, 'B-Frequency': 3, 'B-Coordinate': 4, 'B-Location': 4, 'B-MilitaryPlatform': 5, 'B-Money': 6, 'B-Nationality': 7, 'B-Organisation': 8, 'B-Person': 9, 'B-Quantity': 10, 'B-Temporal': 11, 'B-Url': 12, 'B-Vehicle': 13, 'B-Weapon': 14, 'B-CommsIdentifier': 15, 'I-DocumentReference': 16, 'I-Frequency': 17, 'I-Coordinate': 18, 'I-Location': 18, 'I-MilitaryPlatform': 19, 'I-Money': 20, 'I-Nationality': 21, 'I-Organisation': 22, 'I-Person': 23, 'I-Quantity': 24, 'I-Temporal': 25, 'I-Url': 26, 'I-Vehicle': 27, 'I-Weapon': 28, 'I-CommsIdentifier': 29, 'PAD': 0}\n"
     ]
    }
   ],
   "source": [
    "tag_names_to_idx = {t:i+1 for t,i in tag_names_to_idx.items()}\n",
    "tag_names_to_idx['PAD'] = 0\n",
    "print('Number of tags: {}'.format(len(tag_names_to_idx)))\n",
    "print(tag_names_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like sentiment classification, we need to encode and pad the dataset. In sequence tagger, we take all the time steps for classification. So we need to create a pad function for labels as well. We add `'PAD'` as the tag for paddings in the sentence for each label.\n",
    "\n",
    "Here we provide a padding function and an encoding function for the labels.\n",
    "\n",
    "Some of the tags contain typo like `B-MilitaryPlatfo` instead of `B-MilitaryPlatform`. We can use `difflib.get_close_matches()` to find the closet tags for the typo.\n",
    "\n",
    "https://docs.python.org/3/library/difflib.html#difflib.get_close_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tags_ner(tags, seq_length):\n",
    "    pad_tags = []\n",
    "    for t in tags:\n",
    "        if len(t) >= seq_length:\n",
    "            pad_tags.append(t[:seq_length])\n",
    "        else:\n",
    "            pad = ['PAD']*(seq_length-len(t))\n",
    "            pad.extend(t)\n",
    "            pad_tags.append(pad)\n",
    "        \n",
    "    return pad_tags\n",
    "\n",
    "def tags_encode(data, tag_names_to_idx):\n",
    "    import difflib\n",
    "    \n",
    "    tags_encode = []\n",
    "    \n",
    "    for label in data:\n",
    "        t = []\n",
    "        for tag in label:\n",
    "            if tag in tag_names_to_idx.keys():\n",
    "                t.append(tag_names_to_idx[tag])\n",
    "            else:\n",
    "                similar_t = difflib.get_close_matches(tag, list(tag_names_to_idx.keys()))\n",
    "                t.append(tag_names_to_idx[similar_t[0]])\n",
    "        tags_encode.append(t)\n",
    "    \n",
    "    return np.array(tags_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we process the sentence and labels for both training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762, 20)\n",
      "(762, 20)\n",
      "(191, 20)\n",
      "(191, 20)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 20\n",
    "\n",
    "train_sentences_encode = doc_encoding(train_sentences, vocabulary_ner)\n",
    "train_sentences_pad = pad_text(train_sentences_encode, sequence_length)\n",
    "train_labels_pad =  pad_tags_ner(train_labels, sequence_length)\n",
    "train_labels_encode = tags_encode(train_labels_pad, tag_names_to_idx)\n",
    "\n",
    "test_sentences_encode = doc_encoding(test_sentences, vocabulary_ner)\n",
    "test_sentences_pad = pad_text(test_sentences_encode, sequence_length)\n",
    "test_labels_pad =  pad_tags_ner(test_labels, sequence_length)\n",
    "test_labels_encode = tags_encode(test_labels_pad, tag_names_to_idx)\n",
    "\n",
    "print(train_sentences_pad.shape)\n",
    "print(train_labels_encode.shape)\n",
    "print(test_sentences_pad.shape)\n",
    "print(test_labels_encode.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in section 1, we create the tensor dataset and dataloader for both training and test set in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_tensor = TensorDataset(torch.from_numpy(train_sentences_pad), torch.from_numpy(train_labels_encode))\n",
    "train_loader = DataLoader(train_tensor, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_tensor = TensorDataset(torch.from_numpy(test_sentences_pad), torch.from_numpy(test_labels_encode))\n",
    "test_loader = DataLoader(test_tensor, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For NER, we also need three layers: input, hidden and output layer. The difference is when during feed-forward, we pass all the LSTM out put to FC layer.\n",
    "\n",
    "**TODO 2.1:** Construct the NN for NER. You can adapt the code for the BiLSTM class you used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERBiLSTM(nn.Module):\n",
    "    def __init__(self, n_vocab, n_embed, n_hidden, n_layers, n_class):\n",
    "        super(NERBiLSTM, self).__init__()\n",
    "        \n",
    "        ###WRITE YOUR OWN CODE HERE\n",
    "        self.embedding = nn.Embedding(n_vocab, n_embed)\n",
    "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, batch_first = True, bidirectional=True)\n",
    "        self.fc = nn.Linear(n_hidden*2, n_class)\n",
    "    \n",
    "    def forward(self, sentence): \n",
    "        ###WRITE YOUR OWN CODE HERE\n",
    "                                                        # INPUT   :  (batch_size, seq_length)\n",
    "        embedded_words = self.embedding(sentence)       # (batch_size, seq_length, n_embed)\n",
    "        lstm_out, matrix = self.lstm(embedded_words)    # (batch_size, seq_length, 2*n_hidden)\n",
    "        fc_out = self.fc(lstm_out)                      # (batch_size, seq_length, n_class)\n",
    "        fc_out.transpose_(1,2)                           # (batch_size, n_class, seq_length)\n",
    "\n",
    "    \n",
    "        return fc_out  # dim: batch_size*batch_max_len x num_tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 2.2:** Create a NN with the NERBiLSTM class we wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(vocabulary_ner)+1\n",
    "n_embed = 100  # number of dimension for embeddings\n",
    "n_hidden = 64 # number of hidden unit for BiLSTM\n",
    "n_layers = 1   # number of BiLSTM layer\n",
    "n_class = len(tag_names_to_idx)\n",
    "\n",
    "###WRITE YOUR OWN CODE HERE\n",
    "ner_model = NERBiLSTM(n_vocab, n_embed, n_hidden, n_layers, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 2.3:** Initialise the loss function and optimizer, and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15 Training Loss: 3.2576 Validation Loss: 2.9904 Training Accuracy: 33.0577% Validation Accuracy: 64.9215%\n",
      "Epoch: 2/15 Training Loss: 2.8387 Validation Loss: 2.5238 Training Accuracy: 69.3241% Validation Accuracy: 75.0000%\n",
      "Epoch: 3/15 Training Loss: 2.3647 Validation Loss: 1.9042 Training Accuracy: 74.5013% Validation Accuracy: 78.4817%\n",
      "Epoch: 4/15 Training Loss: 1.6193 Validation Loss: 1.1627 Training Accuracy: 76.3255% Validation Accuracy: 77.6963%\n",
      "Epoch: 5/15 Training Loss: 1.2154 Validation Loss: 1.0799 Training Accuracy: 75.0000% Validation Accuracy: 78.0105%\n",
      "Epoch: 6/15 Training Loss: 1.0951 Validation Loss: 0.9843 Training Accuracy: 76.2927% Validation Accuracy: 79.1623%\n",
      "Epoch: 7/15 Training Loss: 1.0389 Validation Loss: 0.9628 Training Accuracy: 76.5420% Validation Accuracy: 79.1885%\n",
      "Epoch: 8/15 Training Loss: 1.0045 Validation Loss: 0.9294 Training Accuracy: 76.5748% Validation Accuracy: 79.1885%\n",
      "Epoch: 9/15 Training Loss: 0.9670 Validation Loss: 0.9105 Training Accuracy: 76.6010% Validation Accuracy: 79.1885%\n",
      "Epoch: 10/15 Training Loss: 0.9510 Validation Loss: 0.8885 Training Accuracy: 76.6076% Validation Accuracy: 79.1885%\n",
      "Epoch: 11/15 Training Loss: 0.9270 Validation Loss: 0.8769 Training Accuracy: 76.7126% Validation Accuracy: 79.2147%\n",
      "Epoch: 12/15 Training Loss: 0.8981 Validation Loss: 0.8596 Training Accuracy: 76.8635% Validation Accuracy: 79.2932%\n",
      "Epoch: 13/15 Training Loss: 0.8701 Validation Loss: 0.8476 Training Accuracy: 77.1194% Validation Accuracy: 79.4503%\n",
      "Epoch: 14/15 Training Loss: 0.8422 Validation Loss: 0.8331 Training Accuracy: 77.5394% Validation Accuracy: 79.5288%\n",
      "Epoch: 15/15 Training Loss: 0.8256 Validation Loss: 0.8116 Training Accuracy: 78.2021% Validation Accuracy: 80.1309%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NERBiLSTM(\n",
       "  (embedding): Embedding(4382, 100)\n",
       "  (lstm): LSTM(100, 64, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "epoch = 15\n",
    "\n",
    "###WRITE YOUR OWN CODE HERE\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(ner_model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_nn(epoch, ner_model, train_loader, test_loader, loss_fn, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
