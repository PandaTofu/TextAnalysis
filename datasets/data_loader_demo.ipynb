{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "annoying-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pylab\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Use this module to load the data in a convenient format\n",
    "from scienceie_loader import load_tokenized_data, load_data_with_char_offsets, get_entity_span_from_B_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.path.join(os.getcwd(), 'original_datasets')\n",
    "data_train = os.path.join(data_root, 'scienceie2017_train/train2')\n",
    "data_dev = os.path.join(data_root, 'scienceie2017_dev/dev')\n",
    "data_test = os.path.join(data_root, 'semeval_articles_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eleven-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training documents: 350\n",
      "number of dev documents: 50\n",
      "number of test documents: 100\n",
      "Total number of training relations = 680\n",
      "Total number of dev relations = 168\n",
      "Total number of test relations = 196\n"
     ]
    }
   ],
   "source": [
    "# Load the training, dev and test set in tokenized format.\n",
    "# THIS IS THE RECOMMENDED FORMAT TO USE FOR MOST CASES AS IT'S EASIER TO WORK WITH.\n",
    "\n",
    "# train_docs, dev_docs and test_docs are lists, where each entry is a document.\n",
    "# The list entry for each document is a list of tuples, (token, label).\n",
    "# The labels are BIO tags, wher 'B' and 'I' tags also include the type of entity.\n",
    "\n",
    "# train_rels, dev_rels, and test_rels are also lists, where each entry corresponds to a document.\n",
    "# The entry for each document is a list of tuples (label, entity1_start_token_index, entity2_start_token_index).\n",
    "# Therefore the relations are referred to by the index of their first tokens.\n",
    "\n",
    "train_docs, train_rels, _ = load_tokenized_data(data_train)\n",
    "dev_docs, dev_rels, _ = load_tokenized_data(data_dev)\n",
    "test_docs, test_rels, _ = load_tokenized_data(data_test)\n",
    "\n",
    "print(f'number of training documents: {len(train_docs)}')\n",
    "print(f'number of dev documents: {len(dev_docs)}')\n",
    "print(f'number of test documents: {len(test_docs)}')\n",
    "\n",
    "print(f'Total number of training relations = {np.sum([len(train_rels_doc) for train_rels_doc in train_rels])}')\n",
    "print(f'Total number of dev relations = {np.sum([len(dev_rels_doc) for dev_rels_doc in dev_rels])}')\n",
    "print(f'Total number of test relations = {np.sum([len(test_rels_doc) for test_rels_doc in test_rels])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "expired-delicious",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Within', 'O'),\n",
       " ('a', 'O'),\n",
       " ('coalescence', 'B-Process'),\n",
       " ('approach', 'I-Process'),\n",
       " ('as', 'O'),\n",
       " ('successfully', 'O'),\n",
       " ('applied', 'O'),\n",
       " ('earlier', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('light-quark', 'B-Task'),\n",
       " ('sector', 'I-Task'),\n",
       " (',', 'O'),\n",
       " ('we', 'O'),\n",
       " ('have', 'O'),\n",
       " ('evaluated', 'B-Process'),\n",
       " ('transverse-momentum', 'I-Process'),\n",
       " ('dependencies', 'I-Process'),\n",
       " ('of', 'O'),\n",
       " ('charmed', 'B-Material'),\n",
       " ('hadrons', 'I-Material'),\n",
       " ('in', 'O'),\n",
       " ('central', 'B-Process'),\n",
       " ('heavy-ion', 'I-Process'),\n",
       " ('reactions', 'I-Process'),\n",
       " ('at', 'O'),\n",
       " ('RHIC.', 'O'),\n",
       " ('For', 'O'),\n",
       " ('the', 'O'),\n",
       " ('charm-quark', 'B-Material'),\n",
       " ('distributions', 'I-Task'),\n",
       " ('at', 'O'),\n",
       " ('hadronization', 'B-Process'),\n",
       " ('we', 'O'),\n",
       " ('have', 'O'),\n",
       " ('considered', 'O'),\n",
       " ('two', 'O'),\n",
       " ('limiting', 'O'),\n",
       " ('scenarios', 'O'),\n",
       " (',', 'O'),\n",
       " ('i.e.', 'O'),\n",
       " (',', 'O'),\n",
       " ('no', 'O'),\n",
       " ('reinteractions', 'O'),\n",
       " ('(', 'O'),\n",
       " ('using', 'O'),\n",
       " ('spectra', 'B-Material'),\n",
       " ('from', 'O'),\n",
       " ('PYTHIA', 'O'),\n",
       " (')', 'O'),\n",
       " ('and', 'O'),\n",
       " ('complete', 'B-Process'),\n",
       " ('thermalization', 'I-Process'),\n",
       " ('with', 'O'),\n",
       " ('transverse', 'B-Process'),\n",
       " ('flow', 'I-Process'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('bulk', 'O'),\n",
       " ('matter.', 'O'),\n",
       " ('The', 'O'),\n",
       " ('resulting', 'O'),\n",
       " ('J/ψ', 'O'),\n",
       " ('(', 'O'),\n",
       " ('mT-', 'O'),\n",
       " (')', 'O'),\n",
       " ('spectra', 'O'),\n",
       " ('differ', 'O'),\n",
       " ('in', 'O'),\n",
       " ('slope', 'O'),\n",
       " ('by', 'O'),\n",
       " ('up', 'O'),\n",
       " ('to', 'O'),\n",
       " ('a', 'O'),\n",
       " ('factor', 'O'),\n",
       " ('of', 'O'),\n",
       " ('2', 'O'),\n",
       " ('(', 'O'),\n",
       " ('harder', 'O'),\n",
       " ('for', 'O'),\n",
       " ('pQCD', 'B-Material'),\n",
       " ('c-quarks', 'I-Material'),\n",
       " (')', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('the', 'O'),\n",
       " ('integrated', 'B-Process'),\n",
       " ('yield', 'I-Process'),\n",
       " ('is', 'O'),\n",
       " ('about', 'O'),\n",
       " ('a', 'O'),\n",
       " ('factor', 'O'),\n",
       " ('of', 'O'),\n",
       " ('3', 'O'),\n",
       " ('larger', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('thermal', 'O'),\n",
       " ('case.', 'O'),\n",
       " ('For', 'O'),\n",
       " ('D-mesons', 'B-Material'),\n",
       " (',', 'O'),\n",
       " ('we', 'O'),\n",
       " ('found', 'O'),\n",
       " ('that', 'O'),\n",
       " ('the', 'O'),\n",
       " ('difference', 'B-Process'),\n",
       " ('in', 'I-Process'),\n",
       " ('the', 'I-Process'),\n",
       " ('slope', 'I-Process'),\n",
       " ('parameters', 'I-Process'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('pT-spectra', 'B-Task'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('two', 'O'),\n",
       " ('scenarios', 'O'),\n",
       " ('is', 'O'),\n",
       " ('less', 'O'),\n",
       " ('pronounced', 'O'),\n",
       " (',', 'O'),\n",
       " ('but', 'O'),\n",
       " ('their', 'O'),\n",
       " ('elliptic', 'B-Process'),\n",
       " ('flow', 'I-Process'),\n",
       " ('is', 'O'),\n",
       " ('about', 'O'),\n",
       " ('a', 'O'),\n",
       " ('factor', 'O'),\n",
       " ('of', 'O'),\n",
       " ('2', 'O'),\n",
       " ('larger', 'O'),\n",
       " ('for', 'O'),\n",
       " ('pT⩾1.5', 'O'),\n",
       " ('GeV', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('thermalized', 'O'),\n",
       " ('case.', 'O'),\n",
       " ('The', 'O'),\n",
       " ('elliptic', 'B-Process'),\n",
       " ('flow', 'I-Process'),\n",
       " ('pattern', 'I-Process'),\n",
       " ('of', 'O'),\n",
       " ('D-mesons', 'B-Material'),\n",
       " ('was', 'O'),\n",
       " ('found', 'O'),\n",
       " ('to', 'O'),\n",
       " ('be', 'O'),\n",
       " ('essentially', 'O'),\n",
       " ('preserved', 'O'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('single-electron', 'B-Task'),\n",
       " ('decay', 'I-Task'),\n",
       " ('spectra', 'I-Task'),\n",
       " (',', 'O'),\n",
       " ('rendering', 'O'),\n",
       " ('the', 'O'),\n",
       " ('latter', 'O'),\n",
       " ('a', 'O'),\n",
       " ('very', 'O'),\n",
       " ('promising', 'O'),\n",
       " ('observable', 'O'),\n",
       " ('to', 'O'),\n",
       " ('address', 'O'),\n",
       " ('the', 'O'),\n",
       " ('strength', 'O'),\n",
       " ('of', 'O'),\n",
       " ('charm', 'B-Process'),\n",
       " ('reinteractions', 'I-Process'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('QGP.', 'B-Process'),\n",
       " ('The', 'O'),\n",
       " ('present', 'O'),\n",
       " ('study', 'O'),\n",
       " ('can', 'O'),\n",
       " ('be', 'O'),\n",
       " ('straightforwardly', 'O'),\n",
       " ('generalized', 'O'),\n",
       " ('to', 'O'),\n",
       " ('charmed', 'O'),\n",
       " ('baryons', 'B-Material'),\n",
       " ('(', 'O'),\n",
       " ('Λc', 'O'),\n",
       " (')', 'O'),\n",
       " (',', 'O'),\n",
       " ('which', 'O'),\n",
       " ('may', 'O'),\n",
       " ('serve', 'O'),\n",
       " ('as', 'O'),\n",
       " ('a', 'O'),\n",
       " ('complimentary', 'B-Material'),\n",
       " ('probe', 'I-Material'),\n",
       " ('for', 'O'),\n",
       " ('charm-quark', 'B-Process'),\n",
       " ('reinteractions', 'I-Process'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('QGP', 'B-Process'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a document with its sequence labels\n",
    "train_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mathematical-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hyponym-of', 184, 194]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the relations for the example document\n",
    "train_rels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "discrete-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('baryons', 'B-Material')]\n",
      "[('complimentary', 'B-Material'), ('probe', 'I-Material')]\n"
     ]
    }
   ],
   "source": [
    "# print the first entity span\n",
    "print(get_entity_span_from_B_index(train_docs[0], train_rels[0][0][1]))\n",
    "\n",
    "# print the second entity span\n",
    "print(get_entity_span_from_B_index(train_docs[0], train_rels[0][0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "standard-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training documents: 350\n",
      "number of dev documents: 50\n",
      "number of test documents: 100\n"
     ]
    }
   ],
   "source": [
    "# THIS FORMAT REQUIRES YOU TO TOKENISE THE TEXT YOURSELF SO IS ONLY RECOMMENDED \n",
    "# IF YOUR SEQUENCE LABELLING METHOD REQUIRES A SPECIAL KIND OF TOKENISATION.\n",
    "\n",
    "# Load the training, dev and test sets as a list where each entry corresponds to one document and contains\n",
    "# raw text: [\"doc1\", ...], a list of entity annotations as character offsets: [[(1, 2, entity_index), ...], ...],\n",
    "# and a list of relations defined by entity IDs: [[(1, 2), ...], ...].\n",
    "\n",
    "train_docs_chars = load_data_with_char_offsets(data_train)\n",
    "dev_docs_chars = load_data_with_char_offsets(data_dev)\n",
    "test_docs_chars = load_data_with_char_offsets(data_test)\n",
    "\n",
    "print(f'number of training documents: {len(train_docs_chars)}')\n",
    "print(f'number of dev documents: {len(dev_docs_chars)}')\n",
    "print(f'number of test documents: {len(test_docs_chars)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "baking-density",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Within a coalescence approach as successfully applied earlier in the light-quark sector, we have evaluated transverse-momentum dependencies of charmed hadrons in central heavy-ion reactions at RHIC. For the charm-quark distributions at hadronization we have considered two limiting scenarios, i.e., no reinteractions (using spectra from PYTHIA) and complete thermalization with transverse flow of the bulk matter. The resulting J/ψ (mT-)spectra differ in slope by up to a factor of\\xa02 (harder for pQCD c-quarks), and the integrated yield is about a factor of\\xa03 larger in the thermal case. For D-mesons, we found that the difference in the slope parameters of the pT-spectra in the two scenarios is less pronounced, but their elliptic flow is about a factor of\\xa02 larger for pT⩾1.5\\xa0GeV in the thermalized case. The elliptic flow pattern of D-mesons was found to be essentially preserved in the single-electron decay spectra, rendering the latter a very promising observable to address the strength of charm reinteractions in the QGP. The present study can be straightforwardly generalized to charmed baryons (Λc), which may serve as a complimentary probe for charm-quark reinteractions in the QGP.\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sample document\n",
    "train_docs_chars[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "driven-response",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('T1', 'Process', 9, 29),\n",
       " ('T2', 'Process', 97, 139),\n",
       " ('T3', 'Process', 162, 189),\n",
       " ('T4', 'Task', 207, 232),\n",
       " ('T5', 'Process', 349, 372),\n",
       " ('T6', 'Process', 378, 393),\n",
       " ('T7', 'Process', 520, 536),\n",
       " ('T8', 'Process', 620, 654),\n",
       " ('T9', 'Process', 724, 737),\n",
       " ('T10', 'Task', 662, 672),\n",
       " ('T11', 'Process', 812, 833),\n",
       " ('T12', 'Task', 891, 920),\n",
       " ('T13', 'Process', 998, 1018),\n",
       " ('T14', 'Process', 1156, 1182),\n",
       " ('T15', 'Material', 1132, 1151),\n",
       " ('T16', 'Material', 324, 331),\n",
       " ('T17', 'Material', 496, 509),\n",
       " ('T18', 'Material', 837, 845),\n",
       " ('T19', 'Material', 143, 158),\n",
       " ('T20', 'Process', 236, 249),\n",
       " ('T21', 'Material', 592, 600),\n",
       " ('T22', 'Material', 1097, 1104),\n",
       " ('T23', 'Process', 1190, 1193),\n",
       " ('T24', 'Task', 69, 87),\n",
       " ('T25', 'Material', 213, 218),\n",
       " ('T26', 'Process', 1026, 1029)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a set of entities for this document\n",
    "train_docs_chars[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "informed-antique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hyponym-of', 'T22', 'T15')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a set of relations for this document\n",
    "train_docs_chars[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-excess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-dietary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
